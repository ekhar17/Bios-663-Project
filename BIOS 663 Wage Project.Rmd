---
title: "BIOS 663 Group Project - Wage Data"
author: "Wage Groupies"
date: "5/3/2021"
output: html_document
---

```{r,message=FALSE,warning=FALSE}
#applicable packages
library(tidyverse)
library(dplyr)
library(mosaic)
library(car)
#load data - Andrew
wages <- read.csv("~/Bios-663-Project/CPS_85_Wages.txt", sep="")
#load data - Others
#load data - Elena
#wages <- read.csv("CPS_85_Wages.txt", sep="")
```

### Presentation (15 minutes)
1. description of the data
2. description and justification of the analysis 
3. analysis results (including relevant descriptive statistics, tables, and graphs)
4. conclusions and discussions

### EDA

```{r}
#head and missing values
head(wages)
#no missing values in the dataset
a <- sum(complete.cases(wages))
b <- nrow(wages)
print(a)
print(b)
```

```{r,include=FALSE}
##counts of binary variables
#South
tally(wages$south)
#Sex
tally(wages$sex)
#Union
tally(wages$union)
#Race
tally(wages$race)
#Occupation
tally(wages$occupation)
#Sector
tally(wages$sector)
#Marriage
tally(wages$marriage)
```

South|Count
----|----
Lives in South|156
Lives Elsewhere|378

Sex|Count
----|----
Male|289
Female|245

Union|Count
----|----
Union Member|96
Not Union Member|438

Race|Count
----|----
White|440
Hispanic|27
Other|67

Occupation|Count
----|----
Management|55
Sales|38
Clerical|97
Service|83
Professional|105
Other|156

Sector|Count
----|----
Manufacturing|99
Construction|24
Other|411

Marital Status|Count
----|----
Married|350
Unmarried|184


```{r}
##eda histograms of all numeric covariates
#education
wages %>% ggplot(aes(x=education)) + 
  geom_histogram(binwidth=1) + 
  labs(x='Years of Education', y='Count', title = 'Count of Years of Education')
#experience
wages %>% ggplot(aes(x=experience)) + 
  geom_histogram(binwidth=5) + 
  labs(x='Years of Experience', y='Count', title = 'Count of Years of Experience')
#age
wages %>% ggplot(aes(x=age)) + 
  geom_histogram(binwidth=5) + 
  labs(x='Years of Age', y='Count', title = 'Count of Years of Education')
#wage
wages %>% ggplot(aes(x=wage)) + 
  geom_density(fill="dodgerblue1",alpha=0.5) + 
  labs(x='Wage (dollars/hour)', y='Count', title = 'Count of Wages (dollars/hour)')
```

```{r}
mean(wages$wage)
median(wages$wage)
range(wages$wage)
favstats(wages$wage)
```

Correlation plot:
```{r}
library("corrplot")
M <- cor(wages)
corrplot(M, type = "upper")
```

### Interesting Metrics (group)

```{r}
#proportion of wages by sex
a <- wages %>% filter(sex == 1) %>% sum(wages$wage)
b <- wages %>% filter(sex == 0) %>% sum(wages$wage)
c <- a+b
prop_men <- a/c
prop_women <- b/c
print(prop_men)
print(prop_women)
#calculate proportion of men and women in data
d <- count(wages$sex==1)/nrow(wages)
e <- count(wages$sex==0)/nrow(wages)
print(d)
print(e)
```

- Women make up 47% of wages, Men make up 53% of wages but Women make up 46% of observations and men make up 54% of observations.

```{r}
#average wage by sex
tapply(wages$wage, wages$sex, mean)
tapply(wages$wage, wages$sex, median)

ggplot(wages)+geom_boxplot(aes(y=wage,x=as.factor(sex),color=as.factor(sex))) + labs(title="Hourly Wage by Sex",x="Sex (Male(0),Female(1))",y="Wage ($/hour)",color="Sex") 
```

```{r}
#average wage by education level
tapply(wages$wage, wages$education, mean)
tapply(wages$wage, wages$education, median)

```

```{r}
#average wage by residence area
tapply(wages$wage, wages$south, mean)
tapply(wages$wage, wages$south, median)

ggplot(wages)+geom_boxplot(aes(y=wage,x=as.factor(south),color=as.factor(south)))
```


```{r}
#average wage by experience level
plot(tapply(wages$wage, wages$experience, mean))
plot(tapply(wages$wage, wages$experience, median))

```

```{r}
#average wage by union classification
tapply(wages$wage, wages$union, mean)
tapply(wages$wage, wages$union, median)
```

```{r}
#average wage by age
plot(tapply(wages$wage, wages$age, mean))
plot(tapply(wages$wage, wages$age, median))
```

```{r}
#average wage by race level
tapply(wages$wage, wages$race, mean)
tapply(wages$wage, wages$race, median)
```

```{r}
#average wage by occupation
tapply(wages$wage, wages$occupation, mean)
tapply(wages$wage, wages$occupation, median)
```

```{r}
#average wage by sector
tapply(wages$wage, wages$sector, mean)
tapply(wages$wage, wages$sector, median)
```

```{r}
#average wage by marital status
tapply(wages$wage, wages$marriage, mean)
tapply(wages$wage, wages$marriage, median)
```
##########################################################################

### Determining whether to transform variables
```{r}
## Initial Model
model_initial <- lm(wage ~ . ,data = wages)

## Check assumptions
stud_res = rstudent(model_initial)
hist(stud_res, main = "Histogram of the Studentized Residuals - Initial Model", breaks = 20, 
     xlab = "Studentized Residuals")
largest_res = stud_res %>% abs() %>% sort(decreasing = TRUE) %>% head(15)
largest_res
```
One residual has a a studentized residual of 9.21. This could be a potential outlier.
```{r}
wages[171,]
```
This 21 year old with 1 year of experience is getting $44.5/hour, which is a potential outlier. We will keep him in the analysis for now and then reevaluate whether the outlier should be removed for the calculation of the final model. 

We can see that there are many studentized residuals with values > 2, so the model does not fit all of the values well.

```{r}
plot(model_inital$fitted.values, stud_res, ylab = "Studentized Residuals", 
     xlab = "Predicted Values", main = "Studentized Residuals vs Predicted Values Plot - Initial Model")
abline(h=0, lty = 2, col = "blue")
## Heteroskadisity, has fan v shape
ks.test(stud_res, pnorm, 0, 1)
## p-value less than 0.05
```
This means the normality assumption is violated and the homogeneous variance assumption is also violated. We will use boxcox to determine how to transform the dependent variable (wage).

```{r}
library(MASS)
y = MASS::boxcox(model_inital, plotit = TRUE,  lambda = seq(-.1, .1, by = 0.1))

```
The log likelihood is maximized at -0.029292929, so we round down to 0 for interpretability. This means that we will use an ln(y) transformation, which makes sense as this is the variance stabilizing transformation for count data.

We will briefly check to see if the transformation was helpful
```{r}
t_total_reg = lm(log(wage) ~ ., data = wages)

stud_res1 = rstudent(t_total_reg)
hist(stud_res1, main = "Histogram of the Studentized Residuals", breaks = 20, 
     xlab = "Studentized Residuals")
## Looks normal, longish right tail
plot(t_total_reg$fitted.values, stud_res1, ylab = "Studentized Residuals", 
     xlab = "Predicted Values", main = "Plot of Studentized Residuals versus Predicted Values")
abline(h=0, lty = 2, col = "blue")
## Less heteroskadicity, no clear trend

```

We see now the residuals are normally distributed  the residuals have much more homoskedasticity, so the log transformation improved the model. Now we will check if we should transform any of the three continuos covariates.


First all of the variables are scaled to be centered around 0.
```{r}
wages$age = wages$age - mean(wages$age)
wages$education = wages$education - mean(wages$education)
wages$experience = wages$experience - mean(wages$experience)

x = wages$age
x1 = x * log(x)
summary(lm(log(wage)~ x + x1, data =  wages))
## Not significant, so not transform ages

x = wages$education
x1 = x * log(x)
summary(lm(log(wage)~ x + x1, data =  wages))
## Not significant, so not transform education

x = wages$experience
x1 = x * log(x)
summary(lm(log(wage)~ x + x1, data =  wages))
## Not significant, so not transform experience
```

So apart from centering around 0, none of the continuous predictors  will be transformed. 

Now we look at variance inflation factors to examine colinearity.

```{r}
ols_vif_tol(lm(log(wage) ~ ., data = wages)
)

```
We can see that there is high variance inflation for education, experience and age. First we just remove experience since it has the highest VIF and see how that has changed.

```{r}
ols_vif_tol(lm(log(wage) ~ education + south +sex + union+ age+race +occupation +sector +marriage, data = wages)
)

```

All the VIF's are close to one, meaning there is not high collinearity. Thus our full model will be 
```{r}
full_model = lm(log(wage) ~ education + south +sex + union+ age+race +occupation +sector +marriage, data = wages)
summary(full_model)
```

We recheck the assumptions of the full model, to make sure HILE Gauss has been met. 

### Determining whether to transform variables
```{r}

## Check assumptions
stud_res = rstudent(full_model)
hist(stud_res, main = "Histogram of the Studentized Residuals - Initial Model", breaks = 20, 
     xlab = "Studentized Residuals")
largest_res = stud_res %>% abs() %>% sort(decreasing = TRUE) %>% head(15)
largest_res
```
Two observations have a a studentized residual of >4. This could be a potential outlier.
```{r}
wages[171,]
wages[200,]
```
This 21 year old with 1 year of experience is getting \$44.5/hour, which is a potential outlier. The other has a wage of $1 per hour. This is likely a typo??????

########## Insert Mahalanobis Distance analysis

```{r}
nrow(wages)
ncol(wages)
D2 <- mahalanobis(x = wages, center = T, cov = var(wages))
plot(density(D2, bw = 0.5),
     main="Squared Mahalanobis distances, n=534, p=11") ; rug(D2)

qqplot(qchisq(ppoints(nrow(wages)), df = 3), D2,
       main = expression("Q-Q plot of Mahalanobis" * ~D^2 *
                         " vs. quantiles of" * ~ chi[3]^2))
abline(0, 1, col = 'gray')

outlier_removed <- wages %>% filter(wage != 1)
```

```{r}
plot(full_model$fitted.values, stud_res, ylab = "Studentized Residuals", 
     xlab = "Predicted Values", main = "Studentized Residuals vs Predicted Values Plot - Initial Model")
abline(h=0, lty = 2, col = "blue")
## Nice distribution
hist(stud_res)
ks.test(stud_res, pnorm, 0, 1)
## p-value greater than 0.05
```
This means the normality assumption is met and the homogenous variance assumption is also met.


```{r}
#step-wise backward model selection beginning with max model
step(full_model, direction='backward')
```

```{r}
#reduced model
model.2 <- lm(log(wage) ~ education+south+sex+experience+union+race+sector+age + marriage, data = wages)
summary(model.2)
```


```{r}
# Numerical predictors:
# Age, experience, education
colnames(wages)

wages %>% 
  ggplot(.) +
  geom_point(aes(y = wage, x = age, color = factor(race))) +
  facet_grid(union~sex)
```

<<<<<<< HEAD
### ANOVA test for wage by sex

```{r}

```

=======



### ANOVA

```{r}
#Summary stats

#look at wages by sex
#mean wage higher for males
group_by(wages, sex) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by south
#mean wage higher if not in south
group_by(wages, south) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by union
#mean wage higher if in union
group_by(wages, union) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by race
#mean wage highest for white, lowest for hispanic
group_by(wages, race) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by occupation
#mean wage highest for management, lowest for service
group_by(wages, occupation) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by sector
#mean wage higest in sector 1 (manufacturing) lowest in sector 0 (other)
group_by(wages, sector) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)
#look at wages by marriage
#mean wage higher if married
group_by(wages, marriage) %>%
  summarise(
    count = n(),
    mean = mean(wage, na.rm = TRUE),
    sd = sd(wage, na.rm = TRUE)
)


```

```{r}
#Box plots
#install.packages("ggpubr")
library("ggpubr")

#sex
ggboxplot(wages, x = "sex", y = "wage", 
          color = "sex", 
          ylab = "Wage", xlab = "Sex")

#south
ggboxplot(wages, x = "south", y = "wage", 
          color = "south", 
          ylab = "Wage", xlab = "South")

#union
ggboxplot(wages, x = "union", y = "wage", 
          color = "union", 
          ylab = "Wage", xlab = "Union")

#race
ggboxplot(wages, x = "race", y = "wage", 
          color = "race", 
          ylab = "Wage", xlab = "Race")

#occupation
ggboxplot(wages, x = "occupation", y = "wage", 
          color = "occupation", 
          ylab = "Wage", xlab = "Occupation")

#sector
ggboxplot(wages, x = "sector", y = "wage", 
          color = "sector", 
          ylab = "Wage", xlab = "Sector")

#marriage
ggboxplot(wages, x = "marriage", y = "wage", 
          color = "marriage", 
          ylab = "Wage", xlab = "marriage")

```

```{r}
#One-Way ANOVAs

#sex
sex.aov <- aov(wage ~ sex, data = wages)
summary(sex.aov)
#p < 0.0001

#south
south.aov <- aov(wage ~ south, data = wages)
summary(south.aov)
#p = 0.00108

#union
union.aov <- aov(wage ~ union, data = wages)
summary(union.aov)
#p = 0.000174

#race
race.aov <- aov(wage ~ race, data = wages)
summary(race.aov)
#p = 0.0286

#occupation
occupation.aov <- aov(wage ~ occupation, data = wages)
summary(occupation.aov)
#p = 0.258

#sector
sector.aov <- aov(wage ~ sector, data = wages)
summary(sector.aov)
#p = 0.295

#marriage
marriage.aov <- aov(wage ~ marriage, data = wages)
summary(marriage.aov)
#p = 0.0201

#Welch One-Way ANOVA
#install.packages("rstatix")
library("rstatix")

#sex
welch_anova_test(data=wages,formula = wage ~ sex)
#p < 0.0001

#south
welch_anova_test(data=wages,formula = wage ~ south)
#p = 0.0007

#union
welch_anova_test(data=wages,formula = wage ~ union)
#p < 0.0001

#race
welch_anova_test(data=wages,formula = wage ~ race)
#p = 0.032

#occupation
welch_anova_test(data=wages,formula = wage ~ occupation)
#p < 0.0001

#sector
welch_anova_test(data=wages,formula = wage ~ sector)
#p = 0.424

#marriage
welch_anova_test(data=wages,formula = wage ~ marriage)
#p = 0.025

```


```{r}
#Multiple Comparisons
#install.packages("DescTools")
require(DescTools)

#race
ScheffeTest(aov(wage ~ as.factor(race), data = wages))
#none significant

#occupation
ScheffeTest(aov(wage ~ as.factor(occupation), data = wages))
#significant: 
#2 v 1
#3 v 1
#4 v 1
#6 v 1
#5 v 2
#5 v 3
#5 v 4
#6 v 5

#sector
ScheffeTest(aov(wage ~ as.factor(sector), data = wages))
#none significant

```

```{r}
#check assumptions
#install.packages("car")
library(car)

#homogeneity of variance assumption
#sex
plot(sex.aov, 1)
leveneTest(wage ~ as.factor(sex), data = wages)
#NOT MET

#south
plot(south.aov, 1)
leveneTest(wage ~ as.factor(south), data = wages)
#MET 

#union
plot(union.aov, 1)
leveneTest(wage ~ as.factor(union), data = wages)
#MET

#race
plot(race.aov, 1)
leveneTest(wage ~ as.factor(race), data = wages)
#MET

#occupation
plot(occupation.aov, 1)
leveneTest(wage ~ as.factor(occupation), data = wages)
#NOT MET

#sector
plot(sector.aov, 1)
leveneTest(wage ~ as.factor(sector), data = wages)
#MET

#marriage
plot(marriage.aov, 1)
leveneTest(wage ~ as.factor(marriage), data = wages)
#MET



#normality assumption
#sex
plot(sex.aov, 2)
sex.aov_residuals <- residuals(object = sex.aov)
shapiro.test(x = sex.aov_residuals )
#NOT MET

#south
plot(south.aov, 2)
south.aov_residuals <- residuals(object = south.aov)
shapiro.test(x = south.aov_residuals )
#NOT MET 

#union
plot(union.aov, 2)
union.aov_residuals <- residuals(object = union.aov)
shapiro.test(x = union.aov_residuals )
#NOT MET

#race
plot(race.aov, 2)
race.aov_residuals <- residuals(object = race.aov)
shapiro.test(x = race.aov_residuals )
#NOT MET

#occupation
plot(occupation.aov, 2)
occupation.aov_residuals <- residuals(object = occupation.aov)
shapiro.test(x = occupation.aov_residuals )
#NOT MET

#sector
plot(sector.aov, 2)
sector.aov_residuals <- residuals(object = sector.aov)
shapiro.test(x = sector.aov_residuals )
#NOT MET

#marriage
plot(marriage.aov, 2)
marriage.aov_residuals <- residuals(object = marriage.aov)
shapiro.test(x = marriage.aov_residuals )
#NOT MET

```


>>>>>>> c35d1bb5cea6f7f740abb7befc3229f71b815ca5